{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.3"
    },
    "colab": {
      "name": "5.2.1 ~ 5.2.5.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X12VO1JfaGlw"
      },
      "source": [
        "# 5.2  검증 방법"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2ISYkI-deI9D"
      },
      "source": [
        "- 가지고 있는 데이터 특성에 따라 검증 방법을 달라질 수 있기 때문에 아래 여러 검증 방법을 소개한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z0HZ73neaLjg"
      },
      "source": [
        "## 5.2.1 홀드아웃 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PWYyKLdwc3m-"
      },
      "source": [
        "- 전체 데이터셋에서 테스트 데이터를 분리하고 남은 학습 데이터의 일부를 검증 데이터셋으로 또 분리하는 방법입니다.  \n",
        "즉, 전체 데이터를 3개(학습 데이터, 검증 데이터, 테스트 데이터)로 나누게 된다.\n",
        "\n",
        "- 가장 간단하지만 학습 데이터에 손실이 있기 때문에 데이터가 적은 경우에 사용하기 힘들고, 검증을 오직 한번만 진행할 수 있다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHcJdk1raLhC"
      },
      "source": [
        "![img1](https://t1.daumcdn.net/cfile/tistory/998212375C03889419)\n",
        "- 이미지 출처 : [eda-ai-lab.tistory.com](https://t1.daumcdn.net/cfile/tistory/998212375C03889419) "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y6WD4GqFaLd2"
      },
      "source": [
        "## 5.2.2 교차 검증(K-Fold Cross Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BBNQ9exCcMxW"
      },
      "source": [
        "- 데이터를 K개 세트로 분할하고 K회의 홀드아웃 검증을 반복해 나온 각 평가 결과를 평균한 결과를 예측성능으로 평가한다."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4-WqOJ9YaLVe"
      },
      "source": [
        "![img5221](https://mblogthumb-phinf.pstatic.net/MjAyMDEwMDhfMTEy/MDAxNjAyMTM0NjczNDEx.H_Yau1UU4sk56YlDX3cRdt0vS1qUGIJYCjm21Cdc38Ug.NuVwOZLpiOjxsu0Xc_uA2fXQAM2oofd-8rZBXGRhn2Eg.PNG.myksh0903/grid_search_cross_validation.png?type=w800)\n",
        "- 이미지 출처 : https://m.blog.naver.com/myksh0903/222110413015"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29HRYtryZhTf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d98b9a2-a3fa-4e57-f463-fdd72bf915a0"
      },
      "source": [
        "from sklearn.datasets import load_iris\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "from sklearn.model_selection import KFold\n",
        "import numpy as np\n",
        "\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "# 5개의 폴드 세트로 분리하는 KFold 객체와 폴드 세트별 정확도를 담을 리스트 객체 생성.\n",
        "kfold = KFold(n_splits=5)\n",
        "cv_accuracy = []\n",
        "print('붓꽃 데이터 세트 크기:',features.shape[0])\n"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "붓꽃 데이터 세트 크기: 150\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fFjwO73IZhTi",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "67d8526c-5e4d-4b3e-d5d6-17d887bc5040"
      },
      "source": [
        "n_iter = 0\n",
        "\n",
        "# KFold객체의 split( ) 호출하면 폴드 별 학습용, 검증용 테스트의 로우 인덱스를 array로 반환  \n",
        "for train_index, test_index  in kfold.split(features):\n",
        "    # kfold.split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측 \n",
        "    dt_clf.fit(X_train , y_train)    \n",
        "    pred = dt_clf.predict(X_test)\n",
        "    n_iter += 1\n",
        "    # 반복 시 마다 정확도 측정 \n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 개별 iteration별 정확도를 합하여 평균 정확도 계산 \n",
        "print('\\n## 평균 검증 정확도:', np.mean(cv_accuracy)) "
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :1.0, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#1 검증 세트 인덱스:[ 0  1  2  3  4  5  6  7  8  9 10 11 12 13 14 15 16 17 18 19 20 21 22 23\n",
            " 24 25 26 27 28 29]\n",
            "\n",
            "#2 교차 검증 정확도 :0.9667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#2 검증 세트 인덱스:[30 31 32 33 34 35 36 37 38 39 40 41 42 43 44 45 46 47 48 49 50 51 52 53\n",
            " 54 55 56 57 58 59]\n",
            "\n",
            "#3 교차 검증 정확도 :0.8667, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#3 검증 세트 인덱스:[60 61 62 63 64 65 66 67 68 69 70 71 72 73 74 75 76 77 78 79 80 81 82 83\n",
            " 84 85 86 87 88 89]\n",
            "\n",
            "#4 교차 검증 정확도 :0.9333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#4 검증 세트 인덱스:[ 90  91  92  93  94  95  96  97  98  99 100 101 102 103 104 105 106 107\n",
            " 108 109 110 111 112 113 114 115 116 117 118 119]\n",
            "\n",
            "#5 교차 검증 정확도 :0.7333, 학습 데이터 크기: 120, 검증 데이터 크기: 30\n",
            "#5 검증 세트 인덱스:[120 121 122 123 124 125 126 127 128 129 130 131 132 133 134 135 136 137\n",
            " 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 평균 검증 정확도: 0.9\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DozMjSuzaLPd"
      },
      "source": [
        "## 5.2.3 층화 k-겹 검증(Stratified Validation)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U23qoP0BkAws"
      },
      "source": [
        "- 데이터 클래스 별 데이터가 아주 불균형한 상황에서 사용할 수 있는 검증 방법\n",
        "\n",
        "- 가령 금융거래 사기 분류 모델에서 전체 데이터중 정상 거래 건수는 95% 사기인 거래건수는 5% 라면, 앞서 설명한 일반적인 교차 검증으로 데이터를 분할했을 때, 사기 거래 건수가 고루 분할 되지 못하고 한 분할에 몰릴 수 있다. 이때 데이터 클래스 별 분포를 고려해서 데이터 폴드 세트를 만드는 방법이 계층별 k-겹 교차 검증 이다.\n",
        "\n",
        "- 각 데이터 폴드마다 정상 거래건수, 사기 거래 건수가 고루 들어갈 수 있도록 데이터 클래스별 분포를 고려한 분할 방식"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "71KZcfMlwN_Z"
      },
      "source": [
        " "
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ByWBdWwHaUH4"
      },
      "source": [
        "![img5231](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FccXfS2%2FbtqF149CTPE%2Fm94RuE2kgk3ZLs7CCyjsd0%2Fimg.png)\n",
        "- 이미지 출처 : https://huidea.tistory.com/30"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jMEhhzD5ZhTm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "864aa24d-d8d3-4c44-8dc5-3e0d1a26d78e"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "iris = load_iris()\n",
        "\n",
        "iris_df = pd.DataFrame(data=iris.data, columns=iris.feature_names)\n",
        "iris_df['label']=iris.target\n",
        "iris_df['label'].value_counts()\n",
        "\n",
        "# 0번 : Setosa 품종\n",
        "# 1번 : Versicolor 품종\n",
        "# 2번 : Virginica 품종"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "2    50\n",
              "1    50\n",
              "0    50\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-TrkFz0ZhTp",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e81bff63-8bd7-480a-b71e-1773bb7a118a"
      },
      "source": [
        "kfold = KFold(n_splits=3)\n",
        "# kfold.split(X)는 폴드 세트를 3번 반복할 때마다 달라지는 학습/테스트 용 데이터 로우 인덱스 번호 반환. \n",
        "n_iter =0\n",
        "for train_index, test_index  in kfold.split(iris_df):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())\n",
        "    "
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "1    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 0    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 2    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    50\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 1    50\n",
            "0    50\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    50\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2EEmaBkZhTs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2d7bb2cb-2177-4530-a8bb-6d2f1af872eb"
      },
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "\n",
        "skf = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "\n",
        "for train_index, test_index in skf.split(iris_df, iris_df['label']):\n",
        "    n_iter += 1\n",
        "    label_train= iris_df['label'].iloc[train_index]\n",
        "    label_test= iris_df['label'].iloc[test_index]\n",
        "    print('## 교차 검증: {0}'.format(n_iter))\n",
        "    print('학습 레이블 데이터 분포:\\n', label_train.value_counts())\n",
        "    print('검증 레이블 데이터 분포:\\n', label_test.value_counts())"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "## 교차 검증: 1\n",
            "학습 레이블 데이터 분포:\n",
            " 2    34\n",
            "1    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 1    17\n",
            "0    17\n",
            "2    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 2\n",
            "학습 레이블 데이터 분포:\n",
            " 1    34\n",
            "2    33\n",
            "0    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "0    17\n",
            "1    16\n",
            "Name: label, dtype: int64\n",
            "## 교차 검증: 3\n",
            "학습 레이블 데이터 분포:\n",
            " 0    34\n",
            "2    33\n",
            "1    33\n",
            "Name: label, dtype: int64\n",
            "검증 레이블 데이터 분포:\n",
            " 2    17\n",
            "1    17\n",
            "0    16\n",
            "Name: label, dtype: int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BK-n_VcOZhTt",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc8f8dd8-1b5b-4e8e-d84a-0b370c79f5b6"
      },
      "source": [
        "dt_clf = DecisionTreeClassifier(random_state=156)\n",
        "\n",
        "skfold = StratifiedKFold(n_splits=3)\n",
        "n_iter=0\n",
        "cv_accuracy=[]\n",
        "\n",
        "# StratifiedKFold의 split( ) 호출시 반드시 레이블 데이터 셋도 추가 입력 필요  \n",
        "for train_index, test_index  in skfold.split(features, label):\n",
        "    # split( )으로 반환된 인덱스를 이용하여 학습용, 검증용 테스트 데이터 추출\n",
        "    X_train, X_test = features[train_index], features[test_index]\n",
        "    y_train, y_test = label[train_index], label[test_index]\n",
        "    #학습 및 예측 \n",
        "    dt_clf.fit(X_train , y_train)    \n",
        "    pred = dt_clf.predict(X_test)\n",
        "\n",
        "    # 반복 시 마다 정확도 측정 \n",
        "    n_iter += 1\n",
        "    accuracy = np.round(accuracy_score(y_test,pred), 4)\n",
        "    train_size = X_train.shape[0]\n",
        "    test_size = X_test.shape[0]\n",
        "    print('\\n#{0} 교차 검증 정확도 :{1}, 학습 데이터 크기: {2}, 검증 데이터 크기: {3}'\n",
        "          .format(n_iter, accuracy, train_size, test_size))\n",
        "    print('#{0} 검증 세트 인덱스:{1}'.format(n_iter,test_index))\n",
        "    cv_accuracy.append(accuracy)\n",
        "    \n",
        "# 교차 검증별 정확도 및 평균 정확도 계산 \n",
        "print('\\n## 교차 검증별 정확도:', np.round(cv_accuracy, 4))\n",
        "print('## 평균 검증 정확도:', np.mean(cv_accuracy)) "
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "#1 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#1 검증 세트 인덱스:[  0   1   2   3   4   5   6   7   8   9  10  11  12  13  14  15  16  50\n",
            "  51  52  53  54  55  56  57  58  59  60  61  62  63  64  65  66 100 101\n",
            " 102 103 104 105 106 107 108 109 110 111 112 113 114 115]\n",
            "\n",
            "#2 교차 검증 정확도 :0.94, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#2 검증 세트 인덱스:[ 17  18  19  20  21  22  23  24  25  26  27  28  29  30  31  32  33  67\n",
            "  68  69  70  71  72  73  74  75  76  77  78  79  80  81  82 116 117 118\n",
            " 119 120 121 122 123 124 125 126 127 128 129 130 131 132]\n",
            "\n",
            "#3 교차 검증 정확도 :0.98, 학습 데이터 크기: 100, 검증 데이터 크기: 50\n",
            "#3 검증 세트 인덱스:[ 34  35  36  37  38  39  40  41  42  43  44  45  46  47  48  49  83  84\n",
            "  85  86  87  88  89  90  91  92  93  94  95  96  97  98  99 133 134 135\n",
            " 136 137 138 139 140 141 142 143 144 145 146 147 148 149]\n",
            "\n",
            "## 교차 검증별 정확도: [0.98 0.94 0.98]\n",
            "## 평균 검증 정확도: 0.9666666666666667\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PR-2giMxaULO"
      },
      "source": [
        "## 5.2.4 그룹 k-겹 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jdUEyPKZn21o"
      },
      "source": [
        "- 데이터 안에 매우 연관된 그룹이 있을 때 사용\n",
        "- 예를 들어 얼굴인식을 할 때 테스트 데이터에는 훈련 데이터에는 없는 새로운 사람의 얼굴이 들어가야하는 경우 사용"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vA7Kd0J5aUOb"
      },
      "source": [
        "![img5241](https://img1.daumcdn.net/thumb/R1280x0/?scode=mtistory2&fname=https%3A%2F%2Fblog.kakaocdn.net%2Fdn%2FddDZA0%2FbtqvDZYvFpC%2FNB6eUIUMuaFAFKKmREa4x0%2Fimg.png)\n",
        "- 이미지 출처 : https://ssoondata.tistory.com/29"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z6-QTnCLbzzu"
      },
      "source": [
        "- 캐글데이터 다시 체크하기"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TNwuA5_jcRCO",
        "outputId": "f628196a-9ce2-4a87-aa34-f50284b3793d"
      },
      "source": [
        "from sklearn.model_selection import GroupKFold\n",
        "from sklearn.datasets import make_classification\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.datasets import make_blobs\n",
        "\n",
        "logreg = LogisticRegression()\n",
        "\n",
        "# 인위적 데이터셋 생성\n",
        "X, y = make_blobs(n_samples=12, random_state=0)\n",
        "\n",
        "# 처음 세 개의 샘플은 같은 그룹에 속하고\n",
        "# 다음은 네 개의 샘플이 같습니다.\n",
        "groups = [0, 0, 0, 1, 1, 1, 1, 2, 2, 3, 3, 3]  # 어느그룹에 속하는지 알려줘야함\n",
        "\n",
        "scores = cross_val_score(logreg, X, y, groups, cv=GroupKFold(n_splits=3))\n",
        "#  groups, cv=GroupKFold(n_splits=3)) # 어느그룹에 속하는지 알려주고, cv=그룹폴드쓴다고알려주고(3개그룹이라고)\n",
        "\n",
        "print(\"교차 검증 점수:\\n\", scores)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "교차 검증 점수:\n",
            " [0.75       0.6        0.66666667]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ABZQWw13aURd"
      },
      "source": [
        "## 5.2.5 LOO(Leave-One-Out) 검증"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Vh5JLViajEF"
      },
      "source": [
        "![img5251](https://smlee729.github.io/img/2015-03-19-1-loocv/loocv1.png)\n",
        "- 이미지 출처 : [smlee729.github.io](https://smlee729.github.io/r/machine%20learning/2015/03/19/1-loocv.html)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V0aydkUusc2J"
      },
      "source": [
        "# library load\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.model_selection import LeaveOneOut, cross_val_score, KFold\n",
        "\n",
        "# dataset\n",
        "iris = load_iris()\n",
        "features = iris.data\n",
        "label = iris.target\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(iris.data, iris.target, \n",
        "                                                    test_size=0.2, random_state=0)\n",
        "\n",
        "# create object\n",
        "logreg = LogisticRegression() # model\n",
        "loo = LeaveOneOut() # LeaveOneOut model\n",
        "\n",
        "# test validation\n",
        "# LOOCV\n",
        "scores_loo = cross_val_score(logreg, iris.data, iris.target, cv=loo)\n",
        "\n",
        "# K-fold(5)\n",
        "kfold = KFold(n_splits=5, random_state=0, shuffle=True)\n",
        "scores_fold = cross_val_score(logreg, iris.data, iris.target, cv=kfold) # model, train, target, cross validation\n",
        "\n",
        "# cv result\n",
        "print('iris.data.shape \\n{}'.format(iris.data.shape))\n",
        "print('cv number of partition \\n{}'.format(len(scores_loo)))\n",
        "print('mean score_loocv \\n{:.3f}'.format(scores_loo.mean()))\n",
        "print('mean score_kfold \\n{:.3f}'.format(scores_fold.mean()))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}